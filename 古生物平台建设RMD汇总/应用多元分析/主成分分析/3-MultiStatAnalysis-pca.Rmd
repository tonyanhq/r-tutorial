---
title: "应用多元统计-主成分分析"
output: 
  html_document:
    number_sections: TRUE
    toc: TRUE
    toc_float: TRUE
    code_folding: show
    fig_width: 7
    fig_height: 5
    theme: united
    highlight: tango
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

<font size=4 face="微软雅黑">
&emsp;&emsp;在数据分析中，我们常常面对判断某一事物在同类事物中的好坏、优劣程度及其发展规律等问题，然而影响某一事物的特征及发展规律的因素是多元化的，为了更深入地分析，我们需要综合与其相关的各种影响因素进行综合分析和评价。但是，多变量、大样本的数据会带来诸如多重共线性等问题，各影响因素所反映的信息重复，反而会影响统计结果的真实性和科学性。

&emsp;&emsp;为了尽量避免信息重叠和减轻工作量，人们提出了“降维”的思想，找出少数几个互不相关的综合变量来尽可能地反映原来数据所含有得到绝大部分信息，主成分分析和因子分析正是为解决此类问题而产生的多元统计分析方法。

<font size=4 face="微软雅黑">

#什么是主成分

***

<font size=4 face="微软雅黑">

&emsp;&emsp;我们举个例子，如果要将p个特征$X_1,X_2...X_p$上的n个观测可视化，可以绘制出数据的二维散点图，其中每张图都包含p个变量中任意2个变量的n个观测点。但这样会产生$C_p^2=p(p-1)/2$个散点图，比如，当p=10时，就会绘制出45个散点图！如果P很大，那么要观察所有的散点图是非常困难的，而且极有可能出现的情况是，没有一个图是有价值的，因为每张图仅包含了数据集中很小的一部分信息。很明显，当p很大时，需要寻求一个更好的方法来可视化n个观测。因此，特别需要一种对数据的低维表示方式，而这些表示可以尽可能多地包含数据信息。比如，得到一个二维表示来获取数据中的大部分信息，那么就可以在这个低维空间中绘制出观测图像。

&emsp;&emsp;PCA(pricipal component analysis)就是这样一类方法，通过它能够找到一个尽可能包含足够多数据集变异信息的低维表示。PCA的思想是n个观测虽然都存在于p维空间中，但并不是所有维度都有同样的价值，PCA致力于寻找少数尽可能有意义的维度，而这些维度是否有意义是由观测在每一维度上的离散程度所度量的。通过PCA所找到的每一个维度都是原始p个特征的线性组合

#主成分是怎么找到的

***

<font size=4 face="微软雅黑">

&emsp;&emsp;一组变量$X_1,...X_p$的第一主成分是变量标准化线性组合中方差最大的组合，如下所示$$Z_1=\phi_{11}X_1+\phi_{21}X_2+...+\phi_{p1}X_p$$&emsp;&emsp;标准化的含义是，$\sum_{j=1}^p\phi_{j1}^2=1$，其中$\phi_{11},...\phi_{p1}$指的是第一主成分的载荷。同时，这些载荷构成了主成分的载荷向量$\phi_1=(\phi_{11},\phi_{21}...\phi_{p1})^T$。为防止载荷绝对值任意大而导致方差变得任意大，限定这些载荷的平方和为1。

&emsp;&emsp;假设有一个$n\times p$维数据集X，如何计算它的第一主成分呢？因为只对方差感兴趣，所以假定X中的每个变量都经过了中心化处理，其均值为0（即矩阵X在列方向上的均值为0），然后寻求具有如下形式的样本特征值的线性组合：$$z_{i1}=\phi_{11}X_{i1}+\phi_{21}X_{i2}+...+\phi_{p1}X_{ip}$$&emsp;&emsp;使得该线性组合在限定条件下$式1：\sum_{j=1}^p\phi_{j1}^2=1$下有最大的样本方差。换言之，第一主成分的载荷向量在解如下的最优化问题$$式2：\max\limits_{\phi_{11},...,\phi_{p1}}\left\{\frac{1}{n}sum_{i=1}^n(sum_{j=1}^p\phi_{j1}x_{ij})^2\right\},\sum_{j=1}^p\phi_{j1}^2=1$$&emsp;&emsp;将式一代入式2中，将需要最大化的目标函数写成$\frac{1}{n}\sum_{i=1}^nz_{i1}^2$,因为$\frac{1}{n}\sum_{i=1}^nx_{ij}=0$，$z_{11},...z_{n1}$的均值也为0，因此式2中需要最大化的目标函数正是$z_{i1}$的n个值得样本方差。$z_{11},...z_{n1}$即为主成分的得分。

&emsp;&emsp;第一主成分有一个非常合理的解释，载荷向量$\phi_1=(\phi_{11},\phi_{21}...\phi_{p1})^T$定义了一个在向量空间上数据变异最大的方向。如果将这n个数据点$x_1,...x_n$投影到这个方向上，这些投影值就是主成分的得分$z_{11},...z_{n1}$。

&emsp;&emsp;当这组特征的第一主成分$Z_1$确定之后，可以继续寻找第二主成分$Z_2$。第二主成分也是$X_1,...X_p$的线性组合，这个线性组合是与$Z_1$不相关的各种线性组合中方差最大的一个。表现形式类似于第一主成分，在变量很多的数据集中，会有很多个不同的主成分，它们可以用类似的方式定义。

<font size=4 face="微软雅黑">

#总体主成分

***

&emsp;&emsp;接下来我们来看看严格的数学定义。设$x=(x_1,x_2,...x_p)'$为p维随机向量,x的协方差阵为Σ.Σ的特征值$\lambda_1\geq\lambda_2,...\geq\lambda_p$所对应的单位正交特征向量为$a_1,a_2,...a_p$，则称$z_i=a_i'x$为 的第i主成分。 (i=1,2,...p)
<font size=4 face="微软雅黑">

##总体主成分性质
<font size=4 face="微软雅黑">

&emsp;&emsp;知道了总体主成分的定义，我们再来看看它具有怎样的性质呢？

&emsp;&emsp;（1）第i个主成分的方差为$\lambda_i$，并且主分量之间互不相关。
<font size=4 face="微软雅黑">

&emsp;&emsp;（2）总方差等于不相关主成分的方差之和。
<font size=4 face="微软雅黑">

&emsp;&emsp;（3）主成分$z_i$与原始变量$x_i$的相关系数为$\rho($z_i$,$x_i$)=\sqrt{\lambda_k}a_{ik}/\sqrt{\sigma_{ii}}$，其中 $\sigma_{ii}$为原始变量$x_i$的方差。
<font size=4 face="微软雅黑">

&emsp;&emsp;（4）$\lambda_k/\sum\limits_{i=1}^p\lambda_i$为第k个主成分的贡献率，$\sum\limits_{i=1}^m\lambda_k/\sum\limits_{i=1}^p\lambda_i$为前m个主成分的累计贡献率。

<font size=4 face="微软雅黑">

#样本主成分
<font size=4 face="微软雅黑">

***

&emsp;&emsp;前面讨论的是总体主成分，而在实际问题中，一般总体协方差阵与相关阵是未知的，所以需要我们用样本来对于总体进行估计。那么用样本估计总体有两种途径，一是从样本协方差阵出发，另一种是从样本相关阵出发。
<font size=4 face="微软雅黑">

##从样本协差阵出发
<font size=4 face="微软雅黑">

&emsp;&emsp;记样本的协差阵为S，$\lambda_1\geq\lambda_2,...\geq\lambda_p$为S的特征值，$a_1,a_2,...a_p$为相对应的单位正交特征向量，称$z_i=a_i'x$为第i个主分量。
<font size=4 face="微软雅黑">

##从样本相关阵出发
<font size=4 face="微软雅黑">

&emsp;&emsp;记样本的相关阵为R，$\lambda_1\geq\lambda_2,...\geq\lambda_p$为R的特征值，$a_1,a_2,...a_p$为相对应的单位正交特征向量，称$z_i=a_i'x$为第i个主分量。
<font size=4 face="微软雅黑">

#R语言实现

***
<font size=4 face="微软雅黑">

&emsp;&emsp;在R语言中，用`princomp()`函数作主成分分析，具体使用方法我们运用具体例子进行展示。
<font size=4 face="微软雅黑">

&emsp;&emsp;例如，我们抽取了15名学生的身高、体重、胸围和坐高，并对这15名同学的身体4项指标作主成分分析。
<font size=4 face="微软雅黑">

```{r message=FALSE, warning=FALSE}
student<-data.frame(
         x1=c(148,139,160,149,159,142,153,150,151,139,140,161,158,140,137),
         x2=c(41,34,49,36,45,31,43,43,42,31,29,47,49,33,31),
         x3=c(72,71,77,67,80,66,76,77,77,68,64,78,78,67,66),
         x4=c(78,76,86,79,86,76,83,79,80,74,74,84,83,77,73)
) # 将样本以数据框的形式录入
student.pr<-princomp(student,cor=TRUE) # 进行主成分分析
summary(student.pr,loading=TRUE) # 显示主成分结果，显示主成分对应的各列

```

&emsp;&emsp;主成分分析结果中，standard deviation表示的是主成分的标准差，proportion of variance表示方差贡献率，cumulative roportion表示方差累计贡献率,从累计贡献率可以看出，前两个主成分已经达到98%，所以可以只取前两个主成分。由于我们在程序中有loading=TRUE，因此结果列出了载荷的内容，即可以得到前两个主成分的表示形式为$$z_1=-0.504x_1-0.507x_2-0.489x_3-0.5x_4$$$$z_2=0.423x_1-0.172x_2-0.749x_3+0.48x_4$$&emsp;&emsp;第一个主成分对应的系数符号相同，且系数值均在0.5左右，它反映了学生身材的魁梧程度，因此称为大小因子；第二个主成分是高度与围度的差，反映了学生身材的胖瘦，因此称为形体因子。
<font size=4 face="微软雅黑">

#参考文献
<font size=4 face="微软雅黑">

***
[1]薛毅. 统计建模与R软件[M]. 清华大学出版社, 2007.
[2]Gareth James. 统计学习导论 基于R应用 [M]. 机械工业出版社,2015.
<font size=4 face="微软雅黑">